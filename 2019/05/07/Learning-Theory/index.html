<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">

    

    
    <title>Learning_Theory | James Blog</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content>
    
    <meta name="description" content="Learning Theory  Andrew ng lecture note 를 공부하며 정리한 자료입니다 1. Bias / Variance tradeoff    선형 회귀에서 데이터에 해당 하는 모델을 simple($y=\theta_0 + \theta_1 x$)하게 혹은 complex($y=\theta_0 + \theta_1 x + \cdots + \theta">
<meta property="og:type" content="article">
<meta property="og:title" content="Learning_Theory">
<meta property="og:url" content="http://progresivoJS.github.io/2019/05/07/Learning-Theory/index.html">
<meta property="og:site_name" content="James Blog">
<meta property="og:description" content="Learning Theory  Andrew ng lecture note 를 공부하며 정리한 자료입니다 1. Bias / Variance tradeoff    선형 회귀에서 데이터에 해당 하는 모델을 simple($y=\theta_0 + \theta_1 x$)하게 혹은 complex($y=\theta_0 + \theta_1 x + \cdots + \theta">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://i.stack.imgur.com/t0zit.png">
<meta property="og:updated_time" content="2019-05-07T15:37:56.088Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Learning_Theory">
<meta name="twitter:description" content="Learning Theory  Andrew ng lecture note 를 공부하며 정리한 자료입니다 1. Bias / Variance tradeoff    선형 회귀에서 데이터에 해당 하는 모델을 simple($y=\theta_0 + \theta_1 x$)하게 혹은 complex($y=\theta_0 + \theta_1 x + \cdots + \theta">
<meta name="twitter:image" content="https://i.stack.imgur.com/t0zit.png">
    

    

    
        <link rel="icon" href="/css/images/james.jpg">
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/3.3.1/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    


</head>
</html>
<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                        <h2 class="subtitle-wrap">
                            <p class="subtitle">James Data Scientist Blog</p>
                        </h2>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item">
                                    <a class="main-nav-list-link" href="/">Home</a>
                                </li>
                            
                                        
                                    
                                <li class="main-nav-list-item">
                                    <a class="main-nav-list-link" href="/about/index.html">About</a>
                                </li>
                            
                                <li class="main-nav-list-item">
                                    <a class="main-nav-list-link" href="https://github.com/PJamesY">index.github</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search">
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something...">
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>
        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    uncategorized
    </h1>
</div>

                        <div class="main-body-content">
                            <article id="dratf-Learning-Theory" class="article article-single article-type-dratf" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        Learning_Theory
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/2019/05/07/Learning-Theory/" class="article-date">
            <time datetime="2019-05-07T01:46:02.000Z" itemprop="datePublished">2019-05-07</time>
        </a>
    </div>

		

                
            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <font size="6" color="sky blue">Learning Theory</font>

<p>Andrew ng lecture note 를 공부하며 정리한 자료입니다</p>
<font size="4.5" color="orange">1. Bias / Variance tradeoff</font>


<p><img src="https://i.stack.imgur.com/t0zit.png" alt></p>
<p>선형 회귀에서 데이터에 해당 하는 모델을 simple($y=\theta_0 + \theta_1 x$)하게 혹은 complex($y=\theta_0 + \theta_1 x + \cdots + \theta_4 x^4$)하게 만들수 있다.</p>
<p>4차 함수가 아무리 $y$(price) 예측을 잘한다고 할지라도, 새로운 데이터가 들어왔을때에는 정확하게 예측하기는 어렵다. 즉 학습 데이터로 학습한 complex 모델은 다른 데이터(집)에 대해서는 일반화 되지 않은것이라고 할수 있다. generalization error란 반드시 트레이닝 데이터로 나온 error를 측정하는게 아닌 새로운 테스트 데이터가 들어왔을때의 error를 나타낸다.</p>
<p>가장 왼쪽에 있는 모델과 오른쪽에 있는 모델 모두 generalization error가 높다. 하지만 두 모델의 error가 높은 이유는 다르다.<br>먼저 왼쪽 모델을 보면 만약 $(x, y)$ 데이터가 서로 linear 관계가 아니라면 아무리 많은 데이터로 학습을 시켜도 정확하게 예측하기란 쉽지가 않다. 이런 경우 모델의 편향(<strong>bias</strong>)이 크다고 한다 또는 <strong>underfit</strong> 되었다고 한다.</p>
<p>오른쪽 모델인 경우 보통 학습 데이터가 적을때 $(x,y)$ 데이터 상관관계를 폭넓게 반영하지 못하는 경우이다. 이러한 경우 모델의 분산(<strong>variance</strong>)이 크다고 하고 <strong>overfit</strong> 되었다고 한다.</p>
<p><strong>bias</strong>, <strong>variance</strong> 서로 상충관계(trade off) 이다.<br>simple 한 모델이라면 bias는 크고 variance는 작다. 반면에 complex 모델이라면 bias는 작지만 variance는 매욱 크게 된다.</p>
<font size="4.5" color="orange">2. Preliminaries</font>

<p>여기에서는 다음 3가지의 질문을 정의할것이다.<br>첫째, bias variance tradeoff를 formal하게 할수 있을까?<br>둘째, generalization error를 training error로 관계지을수 있을까?<br>셋째, 학습 알고리즘이 잘 학습되고 있는지 증명할수 있는 조건들이 있는가?</p>
<p>위 질문에 답하기 위해 두개의 보조 정리를 애기해보자</p>
<ol>
<li>Union bound</li>
</ol>
<p>$k$개의 모든 사건이 서로 독립적이지 않는 사건 $A_1, A_2, \ldots, A_k$이 있다고 한다면 다음 식이 성립된다.</p>
<script type="math/tex; mode=display">P(A_1 \cup A_2 \cup \cdots \cup A_k) \leq P(A_1) + P(A_2) + \ldots + P(A_k)</script><p>증명은 하지 않겠지만 직관적으로 이해해 보면 사건 간의 교집합이 존재할수 있기 때문에 각각의 사건의 확률의 합은 모든 사건 합의 확률보다는 크다는 것을 알수 있다.</p>
<ol>
<li>Hoeffding inequality</li>
</ol>
<p>서로 동일한 베르누이 분포에서 나온 독립적인 확률 변수(<strong>iid</strong>) $Z_1, Z_2, \ldots, Z_m$가 있다고 하자.</p>
<p>$P(Z_i=1)=\phi$, $P(Z_i=0)=1-\phi$ 라고 표기하고, 확률변수의 평균은 $\widehat \phi = \frac{1}{m}\sum_{i=1}^m Z_i$ 라고 정의 하고, $\gamma &gt; 0$ 보다 크다고 고정한다.</p>
<p>learning theory에서는 $Chernoff bound$라고 하는 식은 다음과 같다.</p>
<script type="math/tex; mode=display">P(\mid \phi - \widehat \phi \mid > \gamma) \leq 2 exp \left( -2 \gamma^2 m\right)</script><p>식이 복잡해 볼수 있지만, 크게 어렵지 않다. 식을 직관적으로 이해해 보면, 만약 데이터의 갯수가 많으면 즉 $m$이 커지면 커질수록 확률변수의 평균($\widehat \phi$)과 측정값($\phi$)의 차이가 클 확률이 줄어든다는 것이다.</p>
<p>이해를 좀더 쉽게 하기 위해서 label $y \in \{0,1\}$ binary classification을 생각해 보자. 학습데이터 $S$는 $D$ 라는 특정 확률분포에서 $m$개 샘플되었다고 해보자. $S = \{ (x^{(i)}, y^{(i)});i = 1,\ldots,m \}$<br>다음과 같이 training error는 hypothesis $h$에 대해서 다음과 같이 쓸수 있다.</p>
<script type="math/tex; mode=display">\widehat \epsilon(h) = \frac{1}{m} \sum_{i=1}^m 1\{h(x^{(i)}) \neq y^{(i)}\}</script><p>training error가 아닌 우리가 알고 싶은 generalization error는 다음과 같이 나타낼수 있다.</p>
<script type="math/tex; mode=display">\epsilon(h) = P_{(x,y) \sim D}\left( h(x) \neq y\right)</script><p>분포 $D$에서 랜덤하게 나온 sample $(x^{(i)}, y^{(i)})$ 을 $h$가 잘못 분류한것을 나타낸다. 다시한번 언급하자면 training data는 분포 $D$에서 샘플링 된다는 것을 가정하는 것이다.</p>
<p>그럼 hypothesis $h_\theta (x) =1\{\theta^T x \geq 0\}$의 파라미터 $\theta$를 찾으려는 식을 알아보자.</p>
<script type="math/tex; mode=display">\widehat \theta = arg min _{\theta} \widehat\epsilon (h_\theta)</script><p>식을 이해해보면, 즉 학습데이터에 대한 에러를 가장 줄이는 $\widehat \theta$를 찾는 것이다</p>
<p>조금 더 깊게 들어가 우리는 hypothesis class $\mathcal{H}$를 정의할것이다. linear classification에서의 $\mathcal{H}$는 다음과 같이 쓸수 있다.</p>
<script type="math/tex; mode=display">\mathcal{H}=\{h_\theta : h_\theta(x)=1 \{\theta^T x \geq 0\}, \theta \in \mathbb{R}^{n+1}\}</script><p>$\mathcal{X}$ input domain 들마다의 classifier 집합이다.</p>
<script type="math/tex; mode=display">\widehat h = argmin_{h\in \mathcal{H}} \widehat \epsilon(h)</script><p>hypothesis $h$는 모든 classifier hypothesis 집합 $\mathcal{H}$ 속에서 가장 학습 데이터에 대한 오류가 작은 것이 $\widehat h$가 될것이다.</p>
<font size="4.5" color="orange">3. The case of finite $\mathcal{H}$</font>

<p>유한개의 hypothesis 들의 집합 $\mathcal{H}=\{h_1, h_2, \ldots, h_k\}$ 로 정의할수 있고, $\mathcal{X}$ input data에 대해 $\{0,1\}$로 mapping 해주는 함수가 $k$개의 있는 것과 같다.</p>
<p>여기서 우리는 두가지를 확인해야 한다.<br>첫번째, 모든 h에 대해서 $\widehat \epsilon (h)$는 $\epsilon(h)$가 될수 있다.<br>두번째, 여기서 나온 error는 $\widehat h$의 generalization error의 상한선(upper bound)이 된다.</p>
<p>$h_i \in \mathcal{H}$를 하나 선택한다. 그리고 베르누이 확률변수($Z$)를 하나 정의한다. $Z$ 는 분포 $\mathcal{D}$에서 샘플된 데이터$(x,y)\sim \mathcal{D}$를 $h_i$가 잘못 분류한 경우를 말한다. $Z=1\{h_i(x) \neq y\}$ 학습 데이터는 동일한 분포 $\mathcal{D}$에서 샘플 되었기 때문에 $Z$와 $Z_i$도 같은 분포에서 나온 확률 변수 임을 알수 있다.</p>
<p>hypothesis의 학습데이터 오류는 확률변수 $Z$의 평균임을 알수 있다.</p>
<script type="math/tex; mode=display">\widehat \epsilon (h_i)=\frac{1}{m}\sum_{i=1}^m Z_j</script><p>$\widehat \epsilon (h_i)$는 $m$개의 확률변수 $Z_j \sim Bern\left(\phi = \epsilon (h_i)\right)$의 평균이다. 여기에서<br>Hoeffding inequality 공식을 적용해보자.</p>
<script type="math/tex; mode=display">P(\mid \epsilon (h_i) - \widehat \epsilon (h_i) \mid > \gamma) \leq 2 exp \left( -2 \gamma^2 m\right)</script><p>식을 이해해 보면 hypothesis $h_i$의 학습데이터에 대한 오류가 generalization error 와 비슷해지는 확률은 데이터의 갯수($m$)이 많아지면 많아질수록 높아지게 된다. 우리는 더 나아가 $h_i$하나의 hypothesis 뿐만 아니라 모든 hypothesis($h \in \mathcal{H}$)에도 적용 되는지 알아보자. 문제를 풀기 위해 $\mid \epsilon (h_i) - \widehat \epsilon (h_i) \mid &gt; \gamma$를 하나의 사건 $A_i$로 표기하도록 하자.</p>
<script type="math/tex; mode=display">P(A_i) \leq 2 exp \left( -2 \gamma^2 m\right)</script><p>위에서 보았던 union bound 정리를 이용해 다음과 같이 정리할수 있다.</p>
<script type="math/tex; mode=display">\begin{matrix}
P\left( \exists h \in \mathcal{H} .\mid \epsilon (h_i) - \widehat \epsilon (h_i) \mid > \gamma \right)
      &=& P(A_1 \cup A_2 \cup \cdots \cup A_k) \\
      &\leq& \sum_{i=1}^kP(A_i) \\
      &\leq& \sum_{i=1}^k2 \exp \left( -2 \gamma^2 m\right) \\
      &=& 2k \exp \left( -2 \gamma^2 m\right) \\
\end{matrix}</script><p>양변을 1에서 빼주면 다음과 같이 써줄수 있다.</p>
<script type="math/tex; mode=display">\begin{matrix}
P\left( \lnot \exists h \in \mathcal{H} .\mid \epsilon (h_i) - \widehat \epsilon (h_i) \mid > \gamma \right)
      &=& P\left( \forall h \in \mathcal{H} .\mid \epsilon (h_i) - \widehat \epsilon (h_i) \mid \leq \gamma \right)  \\
      &\geq& 1-2k \exp \left( -2 \gamma^2 m\right) \\
\end{matrix}</script><p>위 식을 직관적으로 이해하면, $1-2k \exp \left( -2 \gamma^2 m\right)$ 이상의 확률로 $\widehat \epsilon (h_i)$는 $\epsilon (h_i)$의 $\gamma$ 범위 안에 있다. 이것을 <strong>uniform convergence</strong> 라고 부른다</p>
<p><em>Notation</em></p>
<ul>
<li>$\lnot$ : not 이라는 의미입니다.</li>
</ul>
<p>여기에서 관심있는 값은 $m$, $\gamma$, 에러의 확률이다.</p>
<p>$\delta$ = $2k \exp \left( -2 \gamma^2 m\right) &gt; 0$이라고 fix하고, $\gamma$도 특정한 값으로 fix 하면 데이터의 갯수 $m$는 얼마나 필요한지 확인힐수 있다.</p>
<script type="math/tex; mode=display">m \geq \frac{1}{2\gamma ^2} \log \frac{2k}{\delta}</script><p>만약 데이터의 갯수($m$)가 위와 같이 충분히 있으면, 모든 $h \in \mathcal{H}$ 에 대해서 $\mid \epsilon (h_i) - \widehat \epsilon (h_i) \mid \leq \gamma$ 일 확률은 최소 $1-\delta$가 된다. 마찬가지로, 모든 $h \in \mathcal{H}$ 에 대해서 $\mid \epsilon (h_i) - \widehat \epsilon (h_i) \mid &gt; \gamma$ 일 확률은 최대 $\delta$가 된다. 이러한 확률 bound는 우리가 얼마만큼의 데이터가 필요로 하는지 알수 있게 된다. 또한 $m$은 $\log k$에 영향을 많이 받는다. 여기서 $k$는 hypothesis의 갯수이다.</p>
<p>이번에는 $m$과 $\theta$를 고정하고 $\gamma$를 유도하면 다음과 같다.</p>
<script type="math/tex; mode=display">\gamma = \sqrt{\frac{1}{2m} \log \frac{2k}{\delta}}</script><p>모든 $h \in \mathcal{H}$ 에 대해서</p>
<script type="math/tex; mode=display">P\left(\mid \epsilon (h_i) - \widehat \epsilon (h_i) \mid \leq \sqrt{\frac{1}{2m} \log \frac{2k}{\delta}}\right) \geq 1-\delta</script><p>generalization error를 최소화하는 hypothesis $h$는 다음과 같이 정의할수 있다 $h^* = argmin_{h \in \mathcal{H}} \epsilon (h)$ 즉 우리가 찾는 best model이 되는 것이다.</p>
<script type="math/tex; mode=display">\epsilon(\widehat h) \leq \widehat \epsilon (\widehat h) + \gamma \text { : 1번식}</script><script type="math/tex; mode=display">\widehat \epsilon (\widehat h) + \gamma \leq \widehat \epsilon ( h^*) + \gamma \text { : 2번식}</script><script type="math/tex; mode=display">\widehat \epsilon ( h^*) + \gamma \leq \epsilon ( h^*) + 2\gamma \text { : 3번식}</script><p>위 식을 조금 더 이해하기 쉽게 notation을 다시한번 정리해보자.</p>
<p><strong>Notation</strong></p>
<ul>
<li><p>$\widehat h$ : training error를 가장 최소화 하는 hypothesis, $\widehat h = argmin_{h \in \mathcal{H}} \widehat \epsilon (h)$</p>
</li>
<li><p>$\widehat \epsilon(\widehat h)$ : hypothesis $\widehat h$의 training error</p>
</li>
<li><p>$\epsilon(\widehat h)$ : hypothesis $\widehat h$의 generalization error</p>
</li>
</ul>
<p>위 식에 대해서 순서대로 설명을 해보자면, 1번식 같은 경우는 $\widehat h$의 generalization error는 training error 보다 $\gamma$ 만큼 크다는 것이다. 2번식은 $\widehat h$의 training error보다 $h^{star}$의 training error 가 더 크다는 것이다. $\widehat h, h^{star}$의 정의를 잘 생각해보면 이해할수 있을것이다. 3번식은 $h^{star}$의 generalization error 보다 training error가 $\gamma$ 만큼 더 크다는 뜻이다.</p>
<p>이제 다음과 같은 이론 공식을 유도할수 있다.<br>$\mid \mathcal{H} \mid$ = $k$, $m, \delta$를 고정한다.</p>
<p>최소 $1 - \delta$의 확률로</p>
<script type="math/tex; mode=display">\epsilon (\widehat h) \leq \left(min_{h \in \mathcal{H}} \epsilon (h)\right) + 2 \sqrt{\frac{1}{2m} \log \frac{2k}{\delta}}</script><p>$\gamma = \sqrt{\frac{1}{2m} \log \frac{2k}{\delta}}$</p>
<p>$min_{h \in \mathcal{H}} \epsilon (h)=\epsilon ( h^{*})$</p>
<p>위 식에서 trade off 관계를 확인 할수 있다. 만약 hypothesis의 차수를 늘려주게 되면 generalization error ($\epsilon ( h^{*})$) 는 줄어 들것이다. 하지만 hypothesis의 갯수(k)는 늘어가게 되어서 결국 이 것은 bias는 줄어들게 되지만 variance는 커지게 된다. 반대로 hypothesis의 차수가 줄어들면 generalization error는 커지게 되지만 그만큰 hypothesis의 갯수는 줄어들게 되어서 bias /variance 의 tradeoff 관계가 나타나게 된다.</p>

        </div>
        <footer class="article-footer">
            



    <a data-url="http://progresivoJS.github.io/2019/05/07/Learning-Theory/" data-id="cjw7hcz910006e6l5yviogq3i" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "James Park"
        },
        "headline": "Learning_Theory",
        "image": "http://progresivoJS.github.iohttps://i.stack.imgur.com/t0zit.png",
        "keywords": "",
        "genre": "",
        "datePublished": "2019-05-07",
        "dateCreated": "2019-05-07",
        "dateModified": "2019-05-08",
        "url": "http://progresivoJS.github.io/2019/05/07/Learning-Theory/",
        "description": "Learning Theory

Andrew ng lecture note 를 공부하며 정리한 자료입니다
1. Bias / Variance tradeoff



선형 회귀에서 데이터에 해당 하는 모델을 simple($y=\theta_0 + \theta_1 x$)하게 혹은 complex($y=\theta_0 + \theta_1 x + \cdots + \theta"
        "wordCount": 1281
    }
</script>

</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/PJamesY" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2019/05/09/Regularization-and-modelselection/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">newer</strong>
        <p class="article-nav-title">
        
            Regularization and model selection
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2019/05/07/SVM-1/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">older</strong>
        <p class="article-nav-title">SVM</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="no-thumbnail">
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"></p>
                            <p class="item-title"><a href="/2019/05/28/computation-theory-1/" class="title">Theory of computation (1)</a></p>
                            <p class="item-date"><time datetime="2019-05-28T07:29:16.000Z" itemprop="datePublished">2019-05-28</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"></p>
                            <p class="item-title"><a href="/2019/05/25/kmeans/" class="title">k-means clustering</a></p>
                            <p class="item-date"><time datetime="2019-05-25T06:59:18.000Z" itemprop="datePublished">2019-05-25</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"></p>
                            <p class="item-title"><a href="/2019/05/20/deque/" class="title">Data Structure(Deque)</a></p>
                            <p class="item-date"><time datetime="2019-05-20T08:20:18.000Z" itemprop="datePublished">2019-05-20</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"></p>
                            <p class="item-title"><a href="/2019/05/20/Stack/" class="title">Data Structure(Stack)</a></p>
                            <p class="item-date"><time datetime="2019-05-20T07:00:41.000Z" itemprop="datePublished">2019-05-20</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"></p>
                            <p class="item-title"><a href="/2019/05/17/BFS/" class="title">BFS</a></p>
                            <p class="item-date"><time datetime="2019-05-17T13:48:58.000Z" itemprop="datePublished">2019-05-17</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a><span class="archive-list-count">1</span></li></ul>
        </div>
    </div>


            
                

            
                

            
        
    </div>
</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2019 James Park</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

        
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'http://progresivoJS.github.io/2019/05/07/Learning-Theory/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>
