<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">

    

    
    <title>Regularization and model selection | James Blog</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content>
    
    <meta name="description" content="다음과 같은 hypothesis $h_\theta(x)=g(\theta_0 + \theta_1 x + \ldots + \theta_k x^k)$ 가 있을때 $k$를 몇으로 해야 할지 어떻게 정할수 있을까? 즉 몇차로 식을 만드는게 bias / variance trade off 에 있어서 가장 좋은 모델일까를 어떻게 알수 있을까?조금 구체적으로 이해 하기 위">
<meta property="og:type" content="article">
<meta property="og:title" content="Regularization and model selection">
<meta property="og:url" content="http://progresivoJS.github.io/2019/05/09/Regularization-and-modelselection/index.html">
<meta property="og:site_name" content="James Blog">
<meta property="og:description" content="다음과 같은 hypothesis $h_\theta(x)=g(\theta_0 + \theta_1 x + \ldots + \theta_k x^k)$ 가 있을때 $k$를 몇으로 해야 할지 어떻게 정할수 있을까? 즉 몇차로 식을 만드는게 bias / variance trade off 에 있어서 가장 좋은 모델일까를 어떻게 알수 있을까?조금 구체적으로 이해 하기 위">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2019-05-08T15:48:24.735Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Regularization and model selection">
<meta name="twitter:description" content="다음과 같은 hypothesis $h_\theta(x)=g(\theta_0 + \theta_1 x + \ldots + \theta_k x^k)$ 가 있을때 $k$를 몇으로 해야 할지 어떻게 정할수 있을까? 즉 몇차로 식을 만드는게 bias / variance trade off 에 있어서 가장 좋은 모델일까를 어떻게 알수 있을까?조금 구체적으로 이해 하기 위">
    

    

    
        <link rel="icon" href="/css/images/james.jpg">
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/3.3.1/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    


</head>
</html>
<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                        <h2 class="subtitle-wrap">
                            <p class="subtitle">James Data Scientist Blog</p>
                        </h2>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item">
                                    <a class="main-nav-list-link" href="/">Home</a>
                                </li>
                            
                                        
                                    
                                <li class="main-nav-list-item">
                                    <a class="main-nav-list-link" href="/about/index.html">About</a>
                                </li>
                            
                                <li class="main-nav-list-item">
                                    <a class="main-nav-list-link" href="https://github.com/PJamesY">index.github</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search">
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something...">
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>
        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    uncategorized
    </h1>
</div>

                        <div class="main-body-content">
                            <article id="post-Regularization-and-modelselection" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        Regularization and model selection
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/2019/05/09/Regularization-and-modelselection/" class="article-date">
            <time datetime="2019-05-08T15:48:24.000Z" itemprop="datePublished">2019-05-09</time>
        </a>
    </div>

		

                
            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <p>다음과 같은 hypothesis $h_\theta(x)=g(\theta_0 + \theta_1 x + \ldots + \theta_k x^k)$ 가 있을때 $k$를 몇으로 해야 할지 어떻게 정할수 있을까? 즉 몇차로 식을 만드는게 bias / variance trade off 에 있어서 가장 좋은 모델일까를 어떻게 알수 있을까?<br>조금 구체적으로 이해 하기 위해 유한개의 모델을 다음과 같이 정의하겠다. $M={M_1, \ldots, M_d}$ 여기서 $M_i$는 $i$차수의 다항 회귀 모델이다.</p>
<font size="4.5" color="orange">1. Cross Validation</font>

<p>training set $S$가 있다면 우리는 empirical risk minimization 알고리즘에 의해 다음과 같은 과정을 거쳐 최적의 hypothesis를 찾는다.</p>
<ol>
<li><p>데이터셋에 각각의 $M_i$ 모델을 적용한후 hypothesis $h_i$를 얻는다.</p>
</li>
<li><p>가장 낮은 training error를 낸 hypotheses 를 선택한다</p>
</li>
</ol>
<p>위의 방법은 효과적이지는 않다.<br>분명 높은 차수의 hypothesis가 더 낮은 training error를 발생 시킬것이기 때문이다. 따라서 이 방법은 항상 높은 variance, 높은 차수의 hypothesis가 선택 될것이다.</p>
<p>더 효율이 높은 알고리즘은 <strong>Cross validation</strong> 방법이다. 방법은 다음과 같다.</p>
<ol>
<li><p>랜덤하게 데이터셋 $S$를 70%는 $S_{train} : $ training 데이터로, 나머지 30% $S_{cv}$(hold out cross validation set)으로 나눈다.</p>
</li>
<li><p>hypothesis $h_i$를 얻기 위해 $S_{train}$ 데이터만 사용한다.</p>
</li>
<li><p>그리고 가장 작은 에러($\hat \epsilon_{S_{cv}}$)를 낸 hypothesis를 선택하면 된다. (여기서 $\hat \epsilon_{S_{cv}}$ 는 $S_{cv}$ 데이터에 대한 empirical error를 나타낸 것이다.)</p>
</li>
</ol>
<p>$S_{train}$ 데이터로 학습하며 얻은 $h_i$로 학습할때 사용하지 않았던 $S_{cv}$로 테스트를 해보면 $h_i$의 true generalization error를 측정할수 있다. 그 다음 가장 작은 generalization error를 가진 hypothesis를 선택하면 된다. 보통의 경우 데이터의 $1/4, 1/3$ 정도를 cross validation set으로 사용한다.</p>
<p>하지만 위 방법은 30% 정도의 data를 training 할때 쓰지 못한다는 단점이 있다. 학습 할때 즉 항상 $0.7m$의 데이터만 사용하고 전체 데이터 $m$을 사용을 못한다는 것이다. 물론 충분한 엄청 많은 데이터가 있다면 상관없지만…</p>
<p>데이터가 충분하지 않다면 다음 <strong>K-fold Cross Validation</strong> 방법을 쓰는것이 조금더 데이터를 활용할수 있을것이다.</p>
<ol>
<li><p>렌덤하게 데이터 $S$를 $m/k$개로 이루어진 데이터 $k$개로 나눠 준다. 그리고 각각의 데이터 셋을 $S_1, S_2, \ldots, S_k$로 지정한다.</p>
</li>
<li><p>각각의 모델 $M_i$ 에 대해 다음을 실행한다.</p>
<ul>
<li><p>For $j = 1, 2, \ldots, k$</p>
<ul>
<li>S_j 데이터 셋만 제외하고 나머지 데이터 $S_1 \cup \cdots \cup S_{j-1} \cup S_{j+1} \cup \cdots S_k$ 를 가지고 학습을 시킨다음 $h_{ij}$ hypothesis를 얻는다. 그리고 나서 $S_j$데이터를 가지고 테스트를 한후 $\widehat \epsilon (S_j)$ 를 찾는다</li>
</ul>
</li>
<li>$M_i$의 generalization error는 $\widehat \epsilon (S_j)$ 평균으로 구한다.</li>
</ul>
</li>
<li><p>generalization error가 가장 낮은 $M_i$을 구한 다음 다시 전체 데이터 셋 $S$를 가지고 재학습을 하여 얻어진 hypothesis가 최종 답이 된다.</p>
</li>
</ol>
<p>데이터를 나눌때 $1/k$로 전 cross validation보다 훨씬 적게 test로 사용되긴 하였지만, 각각의 모델마다 k번의 계산이 필요하기 때문에 계산적으로는 비효율적이다.</p>
<p>이러한 교차 검증 방법은 single model / algorithm을 검증하고 싶을때 사용하면 좋은 검증 방법중에 하나가 될것이다.</p>
<font size="4.5" color="orange">2. Feature Selection</font>

<p>model을 선택할때 중요하고 특별한 방법중의 하나가 Feature selection이다. 만약 supervised learning을 하려고 하는데 Feature의 갯수가 너무 많으면 ($n &gt;&gt; m$) 모델의 학습에 관련있는 몇개의 feature 만 선택해야 할것이다. simple한 선형 분류문제를 풀때 많은 수($n$)의 feature가 사용되면,  hypothesis class의 VC dimension이 여전히 $O(n)$이기 때문에 학습 데이터가 많지 않은 한 overfitting 문제가 발생할수 있기 때문이다.</p>
<p>만약 n 개의 features가 있다면 feature를 사용할 모든 경우의 수는 $2^n$이 될것이다.</p>
<p>feature selection 방법중에 forward selection는 다음과 같다.</p>
<ol>
<li><p>$\mathcal{F}= \emptyset$</p>
</li>
<li><p>Repeat {</p>
<p> (a) For $i = 1, 2, \ldots, n$ $if$ $i \notin \mathcal{F}$, $\mathcal{F_i}=F \cup \{i\}$로 놓는다. $\mathcal{F_i}$를 평가하기 위해 cross validation 한다. generalization error를 구한다.</p>
<p> (b) step (a)에서 자장 적합한 feature set $\mathcal{F_i}$를 찾는<br>}</p>
</li>
<li><p>전체 과정을 돌고 나서 가장 적합한 feature set을 선택한다.</p>
</li>
</ol>
<p>전체 loop가 종료되는 시점은 The $\mathcal{F}$가 전체 feature set $\{1, \ldots, n\}$이 되었거나, 미리 지정해준 threshold hold $\mid \mathcal{F_i}\mid$ 를 넘었을때이다.</p>
<p>forward selection은 <em>wrapper model feature selection</em> 의 한 예시로 불리기도한다.</p>
<p>forward search 와는 다른 방법인 backward search가 있다. 이 방법은 처음 feature set의 시작을 전체 set $\mathcal{F} = \{1, \ldots, n\}$으로 시작 한다. 그리고 반복적으로 하나씩 feature들을 지워가며 $\mathcal{F}= \emptyset$ 가 될때까지 최적의 feature set을 찾는다.</p>
<p>하지만 이러한 wrapper model feature selection 은 계산 복잡도가 모든 feature set $\mathcal{F} = \{1, \ldots, n\}$ 을 확인할때까지 $O(n^2)$가 된다.</p>
<p>그러한 이유로 비록 heuristic 하긴 하지만, 계산 복잡도가 조금 더 낮은 방법인 <em>Filter feature selection</em> 을 사용할수 있다. 여기서 사용하는 방법은 간단한 점수 $S(i)$를 활용한다. $S(i)$는 하나의 feature $x_i$가 라벨 $y$에 대해 얼마나 정보성이 있느냐의 점수이다. 점수가 큰 feature를 선택하게 된다.</p>
<p>$S(i)$를 측정하는 한가지 방법은 학습 데이터에서 얻은 feature $x$ 와 라벨 $y$간의 서로의 correlation을 점수로 쓰는 것이다. 결국 라벨과 가장 강한 관계가 강한 feature가 점수가 높게 될것이다.  </p>
<p>실제로는 특히 feature $x_i$의 값들이 discrete 할때는 $S(i)$를 상호 정보량($MI(x_i,y)$)으로 수치화 하여 사용한다</p>
<script type="math/tex; mode=display">MI(x_i,y) = \sum_{x_i \in \{0,1\}} \sum_{y \in \{0,1\}} p(x_i, y) \log \frac{p(x_i, y)}{p(x_i)p(y)}</script><p>위의 공식은 $x_i$와 $y$가 binary value로 이루어져 있을때이고,<br>확률 $p(x_i, y)$, $p(x_i),p(y)$ training data의 empirical distribution에 의해 측정 된것이다</p>
<p>상호 정보량이 KL divergence로 표현될수 있다는 것을 이해하고 있으면 위 식을 조금더 직관적으로 이해할수 있을것이다.</p>
<script type="math/tex; mode=display">MI(x_i,y) = KL(p(x_i, y) \mid \mid p(x_i)p(y))</script><p>KL divergence 는 확률 분포 $p(x_i, y)$와 $p(x_i)p(y)$가 얼마나 다른지 나타내는 것이다. 만약 $x_i$와 $y$가 서로 independent 하다면 $p(x_i, y) = p(x_i)p(y)$ 가 성립할것이고, 두 분포간의 KL divergence는 0이 될것이다. 또한 $x_i$가 명백히 $y$에 대한 정보량이 없다는 것을 의마기도 한다. 반대로, 만약 $x_i$가 $y$에 대한 정보량이 많으면 그들의 상호 정보량 $MI(x_i,y)$는 매우 클것이다.</p>
<p>자 그러면 스코어 S(i)를 구하고, 몇개의 feature를 사용할것인가를 정해야 한다. 가장 표준적인 방법은 가능한 k의 갯수를 cross validation을 통해서 구하는 것이다.</p>
<p>보통 이방법은 단어의 갯수가 많은 즉 feature의 갯수가 매우 많은 naive Bayes text classification을 할때 feature 갯수를 줄이기 위해 사용한다.</p>
<font size="4.5" color="orange">3. Bayesian statistics and regularization</font>

<p>이번에는 overfitting을 피하기 위해 쓰이는 방법을 알아보겠다. 우리는 parameter을 찾기 위해 최대 가능도 (maximum likelihood)를 사용한다.</p>
<script type="math/tex; mode=display">\theta_{ML}=argmax_{\theta}\prod_{i=1}^m p(y^{(i)} \mid x{(i)};\theta)</script><p>기존의 최대 가능도 방법은 $\theta$를 random하게 지정하는게 아닌, 모르는 상수로 놓는다.</p>
<p>그러나, maximum likelihood 방법 말고 Bayesian 방법을 이용한 방법을 쓰게 되면 모르는 값 $\theta$를 렌덤하게 놓고, 사전확률 분포 $P(\theta)$를 지정한다.<br>만약 학습 데이터 셋 $S=\{(x^{(i)}, y^{(i)})\}_{i=1}^m$ 이 주어졌을때 $\theta$를 사후 확률 분포 $P(\theta \mid S)$ 통해 예측한다.</p>
<script type="math/tex; mode=display">\begin{matrix}
P(\theta \mid S) &=& \frac{P(S \mid \theta) P(\theta)}{P(S)} \\
       &=& \frac{\left(\prod_{i=1}^m p(y^{(i)}\mid x^{(i)},\theta)\right)p(\theta)}
         {\int_\theta \left(\prod_{i=1}^m p(y^{(i)}\mid x^{(i)},\theta)p(\theta)\right)d\theta}
\end{matrix}</script><p>위 식의 $p(y^{(i)}\mid x^{(i)},\theta)$는 learning 문제를 풀때마다 나오는 식이다. 만약 Bayesian logistic regression 문제를 풀면 $p(y^{(i)}\mid x^{(i)},\theta)=h_\theta(x^{(i)})^{y^{(i)}}(1-h_\theta(x^{(i)}))^{(1-y^{(i)})}$ 가 된다.</p>
<p>$h_\theta(x^{(i)})=1/(1+exp(-\theta x^{(i)}))$</p>
<p>새로운 x데이터에 대해 예측을 하려고 한다면 $\theta$의 사후 확률분포를 활용하여 클래스에 대한 사후 확률 분포를 이용해서 구한다</p>
<p>$p(y \mid x, S)=\int_\theta p(y \mid x, \theta)p(\theta \mid S)d\theta$</p>
<p>$E[y \mid x, S] = \int_y yp(y\mid x,S)dy$</p>
<p>x 데이터가 주어졌을때 $\theta$에대한 사후 확률 분포$p(\theta \mid S)$에 관한  y의 평균으로 구할수 있다.</p>
<p>하지만 Bayesian 방법은 $\theta$의 차수가 커지면 커질수록 계산 복잡도가 커지고, closed form도 아니라서 계산이 어렵다는 단점이 있다.</p>
<p>따라서 $\theta$의 사후 확률 분포를 근사하여 구하게 되는데 이 방법을 MAP(maximum a posterior)라고 한다</p>
<p>$\theta_{MAP}=argmax_\theta \prod_{i=1}^mp(y^{(i)}\mid x^{(i)}, \theta)p(\theta)$</p>
<p>MAP 식을 보면 알겠지만 maximum likelihood와 다른 점은 단지 뒤에 $p(\theta)$만 붙어 있다는 것이다. 뒤에 사전 확률 분포가 곱해져 있으므로 ML보다 overfitting에 대해 덜 민감한 장점이 있다</p>

        </div>
        <footer class="article-footer">
            



    <a data-url="http://progresivoJS.github.io/2019/05/09/Regularization-and-modelselection/" data-id="cjwa7eoo40009qnl5xqrwjsem" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "James Park"
        },
        "headline": "Regularization and model selection",
        "image": "http://progresivoJS.github.io",
        "keywords": "",
        "genre": "",
        "datePublished": "2019-05-09",
        "dateCreated": "2019-05-09",
        "dateModified": "2019-05-09",
        "url": "http://progresivoJS.github.io/2019/05/09/Regularization-and-modelselection/",
        "description": "다음과 같은 hypothesis $h_\theta(x)=g(\theta_0 + \theta_1 x + \ldots + \theta_k x^k)$ 가 있을때 $k$를 몇으로 해야 할지 어떻게 정할수 있을까? 즉 몇차로 식을 만드는게 bias / variance trade off 에 있어서 가장 좋은 모델일까를 어떻게 알수 있을까?조금 구체적으로 이해 하기 위"
        "wordCount": 1016
    }
</script>

</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/PJamesY" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2019/05/13/LDA/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">newer</strong>
        <p class="article-nav-title">
        
            Latent Dirichlet Allocation
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2019/05/07/Learning-Theory/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">older</strong>
        <p class="article-nav-title">Learning_Theory</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="no-thumbnail">
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"></p>
                            <p class="item-title"><a href="/2019/05/30/computation-theory-3/" class="title">Theory of computation (3)</a></p>
                            <p class="item-date"><time datetime="2019-05-30T05:14:05.000Z" itemprop="datePublished">2019-05-30</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"></p>
                            <p class="item-title"><a href="/2019/05/29/computation-theory-2/" class="title">Theory of computation (2)</a></p>
                            <p class="item-date"><time datetime="2019-05-29T06:28:12.000Z" itemprop="datePublished">2019-05-29</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"></p>
                            <p class="item-title"><a href="/2019/05/28/computation-theory-1/" class="title">Theory of computation (1)</a></p>
                            <p class="item-date"><time datetime="2019-05-28T07:29:16.000Z" itemprop="datePublished">2019-05-28</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"></p>
                            <p class="item-title"><a href="/2019/05/25/kmeans/" class="title">k-means clustering</a></p>
                            <p class="item-date"><time datetime="2019-05-25T06:59:18.000Z" itemprop="datePublished">2019-05-25</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"></p>
                            <p class="item-title"><a href="/2019/05/20/deque/" class="title">Data Structure(Deque)</a></p>
                            <p class="item-date"><time datetime="2019-05-20T08:20:18.000Z" itemprop="datePublished">2019-05-20</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a><span class="archive-list-count">1</span></li></ul>
        </div>
    </div>


            
                

            
                

            
        
    </div>
</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2019 James Park</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

        
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'http://progresivoJS.github.io/2019/05/09/Regularization-and-modelselection/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>
